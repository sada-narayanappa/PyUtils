{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Description: Tokenise an Excel formula using an implementation of\n",
    "#              E. W. Bachtal's algorithm, found here:\n",
    "#\n",
    "#                  http://ewbi.blogs.com/develops/2004/12/excel_formula_p.html\n",
    "#\n",
    "#              Tested with Python v2.5 (win32)\n",
    "#      Author: Robin Macharg\n",
    "#   Copyright: Algorithm (c) E. W. Bachtal, this implementation (c) R. Macharg\n",
    "#\n",
    "# CVS Info:\n",
    "# $Header: T:\\\\cvsarchive/Excel\\040export\\040&\\040import\\040XML/ExcelXMLTransform/EWBI_Javascript_port/jsport.py,v 1.5 2006/12/07 13:41:08 rmacharg Exp $\n",
    "#\n",
    "# Modification History\n",
    "#\n",
    "# Date         Author Comment\n",
    "# =======================================================================\n",
    "# 2006/11/29 - RMM  - Made strictly class-based.\n",
    "#                     Added parse, render and pretty print methods\n",
    "# 2006/11    - RMM  - RMM = Robin Macharg\n",
    "#                           Created\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "#       Class: ExcelParserTokens\n",
    "# Description: Inheritable container for token definitions\n",
    "#\n",
    "#  Attributes: Self explanatory\n",
    "#\n",
    "#     Methods: None\n",
    "#========================================================================\n",
    "class f_token:\n",
    "    def __init__(self, value, type, subtype):\n",
    "        self.tvalue   = value\n",
    "        self.ttype    = type\n",
    "        self.tsubtype = subtype\n",
    "    def tostr(self):\n",
    "        t = self;\n",
    "        return t.tvalue + \" <\" + t.ttype +\"> <\" + t.tsubtype\n",
    "     \n",
    "class ExcelParserTokens:\n",
    "    TOK_TYPE_NOOP           = \"noop\";\n",
    "    TOK_TYPE_OPERAND        = \"operand\";\n",
    "    TOK_TYPE_FUNCTION       = \"function\";\n",
    "    TOK_TYPE_SUBEXPR        = \"subexpression\";\n",
    "    TOK_TYPE_ARGUMENT       = \"argument\";\n",
    "    TOK_TYPE_OP_PRE         = \"operator-prefix\";\n",
    "    TOK_TYPE_OP_IN          = \"operator-infix\";\n",
    "    TOK_TYPE_OP_POST        = \"operator-postfix\";\n",
    "    TOK_TYPE_WSPACE         = \"white-space\";\n",
    "    TOK_TYPE_UNKNOWN        = \"unknown\"\n",
    "    \n",
    "    TOK_SUBTYPE_START       = \"start\";\n",
    "    TOK_SUBTYPE_STOP        = \"stop\";\n",
    "    TOK_SUBTYPE_TEXT        = \"text\";\n",
    "    TOK_SUBTYPE_NUMBER      = \"number\";\n",
    "    TOK_SUBTYPE_LOGICAL     = \"logical\";\n",
    "    TOK_SUBTYPE_ERROR       = \"error\";\n",
    "    TOK_SUBTYPE_RANGE       = \"range\";\n",
    "    TOK_SUBTYPE_MATH        = \"math\";\n",
    "    TOK_SUBTYPE_CONCAT      = \"concatenate\";\n",
    "    TOK_SUBTYPE_INTERSECT   = \"intersect\";\n",
    "    TOK_SUBTYPE_UNION       = \"union\";\n",
    "\n",
    "#========================================================================\n",
    "#       Class: f_token \n",
    "# Description: Encapsulate a formula token\n",
    "#\n",
    "#  Attributes:   tvalue - \n",
    "#                 ttype - See token definitions, above, for values\n",
    "#              tsubtype - See token definitions, above, for values\n",
    "#\n",
    "#     Methods: f_token  - __init__()\n",
    "#========================================================================\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "#       Class: f_tokens \n",
    "# Description: An ordered list of tokens\n",
    "\n",
    "#  Attributes:        items - Ordered list \n",
    "#                     index - Current position in the list\n",
    "#\n",
    "#     Methods: f_tokens     - __init__()\n",
    "#              f_token      - add()      - Add a token to the end of the list\n",
    "#              None         - addRef()   - Add a token to the end of the list\n",
    "#              None         - reset()    - reset the index to -1\n",
    "#              Boolean      - BOF()      - End of list?\n",
    "#              Boolean      - EOF()      - Beginning of list?\n",
    "#              Boolean      - moveNext() - Move the index along one\n",
    "#              f_token/None - current()  - Return the current token\n",
    "#              f_token/None - next()     - Return the next token (leave the index unchanged)\n",
    "#              f_token/None - previous() - Return the previous token (leave the index unchanged)\n",
    "#========================================================================\n",
    "class f_tokens:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "        self.index = -1\n",
    "  \n",
    "    def add(self, value, type, subtype=\"\"):\n",
    "        if (not subtype):\n",
    "            subtype = \"\"\n",
    "        token = f_token(value, type, subtype)\n",
    "        self.addRef(token)\n",
    "        return token\n",
    "        \n",
    "    def addRef(self, token):\n",
    "        self.items.append(token)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.index = -1\n",
    " \n",
    "    def BOF(self):\n",
    "        return self.index <= 0\n",
    "\n",
    "    def EOF(self):\n",
    "        return self.index >= (len(self.items) - 1)\n",
    "\n",
    "    def moveNext(self):\n",
    "        if self.EOF():\n",
    "            return False\n",
    "        self.index += 1\n",
    "        return True\n",
    "    \n",
    "    def current(self):\n",
    "        if self.index == -1:\n",
    "            return None\n",
    "        return self.items[self.index]\n",
    "\n",
    "    def next(self):\n",
    "        if self.EOF():\n",
    "            return None\n",
    "        return self.items[self.index + 1]\n",
    "    \n",
    "    def previous(self):\n",
    "        if self.index < 1:\n",
    "            return None\n",
    "        return self.items[self.index -1]\n",
    "\n",
    "#========================================================================\n",
    "#       Class: f_tokenStack \n",
    "#    Inherits: ExcelParserTokens - a list of token values\n",
    "# Description: A LIFO stack of tokens\n",
    "#\n",
    "#  Attributes:        items - Ordered list \n",
    "#\n",
    "#     Methods: f_tokenStack - __init__()\n",
    "#              None         - push(token) - Push a token onto the stack\n",
    "#              f_token/None - pop()       - Pop a token off the stack\n",
    "#              f_token/None - token()     - Non-destructively return the top item on the stack\n",
    "#              String       - type()      - Return the top token's type\n",
    "#              String       - subtype()   - Return the top token's subtype\n",
    "#              String       - value()     - Return the top token's value\n",
    "#========================================================================\n",
    "class f_tokenStack(ExcelParserTokens):\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "    \n",
    "    def push(self, token):\n",
    "        self.items.append(token)\n",
    "    \n",
    "    def pop(self):\n",
    "        token = self.items.pop()\n",
    "        return f_token(\"\", token.ttype, self.TOK_SUBTYPE_STOP)\n",
    "        \n",
    "    def token(self):\n",
    "        # Note: this uses Pythons and/or \"hack\" to emulate C's ternary operator (i.e. cond ? exp1 : exp2)\n",
    "        return ((len(self.items) > 0) and [self.items[len(self.items) - 1]] or [None])[0]\n",
    "    \n",
    "    def value(self):\n",
    "        return ((self.token()) and [(self.token()).tvalue] or [\"\"])[0]    \n",
    "\n",
    "    def type(self):\n",
    "        t = self.token()\n",
    "        return ((self.token()) and [(self.token()).ttype] or [\"\"])[0]\n",
    "    \n",
    "    def subtype(self):\n",
    "        return ((self.token()) and [(self.token()).tsubtype] or [\"\"])[0]\n",
    "\n",
    "#========================================================================\n",
    "#       Class: ExcelParser\n",
    "# Description: Parse an Excel formula into a stream of tokens\n",
    "\n",
    "#  Attributes:\n",
    "#\n",
    "#     Methods: f_tokens - getTokens(formula) - return a token stream (list)\n",
    "#========================================================================\n",
    "class ExcelParser(ExcelParserTokens):\n",
    "    def getTokens(self, formula):\n",
    "    \n",
    "        def currentChar():\n",
    "            return formula[offset]\n",
    "    \n",
    "        def doubleChar():\n",
    "            return formula[offset:offset+2]\n",
    "        \n",
    "        def nextChar():\n",
    "            # JavaScript returns an empty string if the index is out of bounds,\n",
    "            # Python throws an IndexError.  We mimic this behaviour here.\n",
    "            try:\n",
    "                formula[offset+1]\n",
    "            except IndexError:\n",
    "                return \"\"\n",
    "            else:            \n",
    "                return formula[offset+1]\n",
    "        \n",
    "        def EOF():\n",
    "            return offset >= len(formula)\n",
    "    \n",
    "        tokens     = f_tokens()\n",
    "        tokenStack = f_tokenStack()\n",
    "        offset     = 0\n",
    "        token      = \"\"\n",
    "        inString   = False\n",
    "        inPath     = False\n",
    "        inRange    = False\n",
    "        inError    = False\n",
    "    \n",
    "        while (len(formula) > 0):\n",
    "            if (formula[0] == \" \"):\n",
    "                formula = formula[1:]\n",
    "            else:\n",
    "                if (formula[0] == \"=\"):\n",
    "                    formula = formula[1:]\n",
    "                break;    \n",
    "    \n",
    "        # state-dependent character evaluation (order is important)\n",
    "        while not EOF():\n",
    "               \n",
    "            # double-quoted strings\n",
    "            # embeds are doubled\n",
    "            # end marks token\n",
    "            if inString:\n",
    "                if currentChar() == \"\\\"\":\n",
    "                    if nextChar() == \"\\\"\":\n",
    "                        token += \"\\\"\"\n",
    "                        offset += 1\n",
    "                    else:\n",
    "                        inString = False\n",
    "                        tokens.add(token, self.TOK_TYPE_OPERAND, self.TOK_SUBTYPE_TEXT)\n",
    "                        token = \"\"\n",
    "                else:\n",
    "                    token += currentChar()\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # single-quoted strings (links)\n",
    "            # embeds are double\n",
    "            # end does not mark a token\n",
    "            if inPath:\n",
    "                if currentChar() == \"'\":\n",
    "                    if nextChar() == \"'\":\n",
    "                        token += \"'\"\n",
    "                        offset += 1\n",
    "                    else:\n",
    "                        inPath = False\n",
    "                else:\n",
    "                    token += currentChar()\n",
    "                offset += 1;\n",
    "                continue;    \n",
    "    \n",
    "            # bracketed strings (range offset or linked workbook name)\n",
    "            # no embeds (changed to \"()\" by Excel)\n",
    "            # end does not mark a token\n",
    "            if inRange:\n",
    "                if currentChar() == \"]\":\n",
    "                    inRange = False\n",
    "                token += currentChar()\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # error values\n",
    "            # end marks a token, determined from absolute list of values\n",
    "            if inError:\n",
    "                token += currentChar()\n",
    "                offset += 1\n",
    "                if \",#NULL!,#DIV/0!,#VALUE!,#REF!,#NAME?,#NUM!,#N/A,\".find(\",\" + token + \",\") != -1:\n",
    "                    inError = False\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND, self.TOK_SUBTYPE_ERROR)\n",
    "                    token = \"\"\n",
    "                continue;\n",
    "    \n",
    "            # independent character evaulation (order not important)\n",
    "            #\n",
    "            # establish state-dependent character evaluations\n",
    "            if currentChar() == \"\\\"\":\n",
    "                if len(token) > 0:\n",
    "                    # not expected\n",
    "                    tokens.add(token, self.TOK_TYPE_UNKNOWN)\n",
    "                    token = \"\"\n",
    "                inString = True\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            if currentChar() == \"'\":\n",
    "                if len(token) > 0:\n",
    "                    # not expected\n",
    "                    tokens.add(token, self.TOK_TYPE_UNKNOWN)\n",
    "                    token = \"\"\n",
    "                inPath = True\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            if (currentChar() == \"[\"):\n",
    "                inRange = True\n",
    "                token += currentChar()\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            if (currentChar() == \"#\"):\n",
    "                if (len(token) > 0):\n",
    "                    # not expected\n",
    "                    tokens.add(token, self.TOK_TYPE_UNKNOWN)\n",
    "                    token = \"\"\n",
    "                inError = True\n",
    "                token += currentChar()\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # mark start and end of arrays and array rows\n",
    "            if (currentChar() == \"{\"):\n",
    "                if (len(token) > 0):\n",
    "                    # not expected\n",
    "                    tokens.add(token, self.TOK_TYPE_UNKNOWN)\n",
    "                    token = \"\"\n",
    "                tokenStack.push(tokens.add(\"ARRAY\", self.TOK_TYPE_FUNCTION, self.TOK_SUBTYPE_START))\n",
    "                tokenStack.push(tokens.add(\"ARRAYROW\", self.TOK_TYPE_FUNCTION, self.TOK_SUBTYPE_START))\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            if (currentChar() == \";\"):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                tokens.addRef(tokenStack.pop())\n",
    "                tokens.add(\",\", self.TOK_TYPE_ARGUMENT)\n",
    "                tokenStack.push(tokens.add(\"ARRAYROW\", self.TOK_TYPE_FUNCTION, self.TOK_SUBTYPE_START))\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            if (currentChar() == \"}\"):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                tokens.addRef(tokenStack.pop())\n",
    "                tokens.addRef(tokenStack.pop())\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # trim white-space\n",
    "            if (currentChar() == \" \"):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                tokens.add(\"\", self.TOK_TYPE_WSPACE)\n",
    "                offset += 1\n",
    "                while ((currentChar() == \" \") and (not EOF())):\n",
    "                    offset += 1\n",
    "                continue\n",
    "    \n",
    "            # multi-character comparators\n",
    "            if (\",>=,<=,<>,\".find(\",\" + doubleChar() + \",\") != -1):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                tokens.add(doubleChar(), self.TOK_TYPE_OP_IN, self.TOK_SUBTYPE_LOGICAL)\n",
    "                offset += 2\n",
    "                continue\n",
    "    \n",
    "            # standard infix operators\n",
    "            if (\"+-*/^&=><\".find(currentChar()) != -1):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                tokens.add(currentChar(), self.TOK_TYPE_OP_IN)\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # standard postfix operators\n",
    "            if (\"%\".find(currentChar()) != -1):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                tokens.add(currentChar(), self.TOK_TYPE_OP_POST)\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # start subexpression or function\n",
    "            if (currentChar() == \"(\"):\n",
    "                if (len(token) > 0):\n",
    "                    tokenStack.push(tokens.add(token, self.TOK_TYPE_FUNCTION, self.TOK_SUBTYPE_START))\n",
    "                    token = \"\"\n",
    "                else:\n",
    "                    tokenStack.push(tokens.add(\"\", self.TOK_TYPE_SUBEXPR, self.TOK_SUBTYPE_START))\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # function, subexpression, array parameters\n",
    "            if (currentChar() == \",\"):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                if (not (tokenStack.type() == self.TOK_TYPE_FUNCTION)):\n",
    "                    tokens.add(currentChar(), self.TOK_TYPE_OP_IN, self.TOK_SUBTYPE_UNION)\n",
    "                else:\n",
    "                    tokens.add(currentChar(), self.TOK_TYPE_ARGUMENT)\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # stop subexpression\n",
    "            if (currentChar() == \")\"):\n",
    "                if (len(token) > 0):\n",
    "                    tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "                    token = \"\"\n",
    "                tokens.addRef(tokenStack.pop())\n",
    "                offset += 1\n",
    "                continue\n",
    "    \n",
    "            # token accumulation\n",
    "            token += currentChar()\n",
    "            offset += 1\n",
    "    \n",
    "        # dump remaining accumulation\n",
    "        if (len(token) > 0): \n",
    "            tokens.add(token, self.TOK_TYPE_OPERAND)\n",
    "    \n",
    "        # move all tokens to a new collection, excluding all unnecessary white-space tokens\n",
    "        tokens2 = f_tokens()\n",
    "    \n",
    "        while (tokens.moveNext()):\n",
    "            token = tokens.current();\n",
    "    \n",
    "            if (token.ttype == self.TOK_TYPE_WSPACE):\n",
    "                if ((tokens.BOF()) or (tokens.EOF())):\n",
    "                    pass\n",
    "                elif (not(\n",
    "                     ((tokens.previous().ttype == self.TOK_TYPE_FUNCTION) and (tokens.previous().tsubtype == self.TOK_SUBTYPE_STOP)) or \n",
    "                     ((tokens.previous().ttype == self.TOK_TYPE_SUBEXPR) and (tokens.previous().tsubtype == self.TOK_SUBTYPE_STOP)) or \n",
    "                     (tokens.previous().ttype == self.TOK_TYPE_OPERAND)\n",
    "                    )\n",
    "                  ):\n",
    "                    pass\n",
    "                elif (not(\n",
    "                     ((tokens.next().ttype == self.TOK_TYPE_FUNCTION) and (tokens.next().tsubtype == self.TOK_SUBTYPE_START)) or\n",
    "                     ((tokens.next().ttype == self.TOK_TYPE_SUBEXPR) and (tokens.next().tsubtype == self.TOK_SUBTYPE_START)) or\n",
    "                     (tokens.next().ttype == self.TOK_TYPE_OPERAND)\n",
    "                     )\n",
    "                   ):\n",
    "                    pass\n",
    "                else:\n",
    "                    tokens2.add(token.tvalue, self.TOK_TYPE_OP_IN, self.TOK_SUBTYPE_INTERSECT)\n",
    "                continue\n",
    "    \n",
    "            tokens2.addRef(token);\n",
    "    \n",
    "        # switch infix \"-\" operator to prefix when appropriate, switch infix \"+\" operator to noop when appropriate, identify operand \n",
    "        # and infix-operator subtypes, pull \"@\" from in front of function names\n",
    "        while (tokens2.moveNext()):\n",
    "            token = tokens2.current()\n",
    "            if ((token.ttype == self.TOK_TYPE_OP_IN) and (token.tvalue == \"-\")):\n",
    "                if (tokens2.BOF()):\n",
    "                    token.ttype = self.TOK_TYPE_OP_PRE\n",
    "                elif (\n",
    "                   ((tokens2.previous().ttype == self.TOK_TYPE_FUNCTION) and (tokens2.previous().tsubtype == self.TOK_SUBTYPE_STOP)) or\n",
    "                   ((tokens2.previous().ttype == self.TOK_TYPE_SUBEXPR) and (tokens2.previous().tsubtype == self.TOK_SUBTYPE_STOP)) or\n",
    "                   (tokens2.previous().ttype == self.TOK_TYPE_OP_POST) or \n",
    "                   (tokens2.previous().ttype == self.TOK_TYPE_OPERAND)\n",
    "                  ):\n",
    "                    token.tsubtype = self.TOK_SUBTYPE_MATH;\n",
    "                else:\n",
    "                    token.ttype = self.TOK_TYPE_OP_PRE\n",
    "                continue\n",
    "    \n",
    "            if ((token.ttype == self.TOK_TYPE_OP_IN) and (token.tvalue == \"+\")):\n",
    "                if (tokens2.BOF()):\n",
    "                    token.ttype = self.TOK_TYPE_NOOP\n",
    "                elif (\n",
    "                   ((tokens2.previous().ttype == self.TOK_TYPE_FUNCTION) and (tokens2.previous().tsubtype == self.TOK_SUBTYPE_STOP)) or \n",
    "                   ((tokens2.previous().ttype == self.TOK_TYPE_SUBEXPR) and (tokens2.previous().tsubtype == self.TOK_SUBTYPE_STOP)) or \n",
    "                   (tokens2.previous().ttype == self.TOK_TYPE_OP_POST) or \n",
    "                   (tokens2.previous().ttype == self.TOK_TYPE_OPERAND)\n",
    "                  ):\n",
    "                    token.tsubtype = self.TOK_SUBTYPE_MATH\n",
    "                else:\n",
    "                    token.ttype = self.TOK_TYPE_NOOP\n",
    "                continue\n",
    "    \n",
    "            if ((token.ttype == self.TOK_TYPE_OP_IN) and (len(token.tsubtype) == 0)):\n",
    "                if ((\"<>=\").find(token.tvalue[0:1]) != -1):\n",
    "                    token.tsubtype = self.TOK_SUBTYPE_LOGICAL\n",
    "                elif (token.tvalue == \"&\"):\n",
    "                    token.tsubtype = self.TOK_SUBTYPE_CONCAT\n",
    "                else:\n",
    "                    token.tsubtype = self.TOK_SUBTYPE_MATH\n",
    "                continue\n",
    "        \n",
    "            if ((token.ttype == self.TOK_TYPE_OPERAND) and (len(token.tsubtype) == 0)):\n",
    "                try:\n",
    "                    float(token.tvalue)\n",
    "                #except (ValueError, e:\n",
    "                except ValueError:\n",
    "\n",
    "                    if ((token.tvalue == 'TRUE') or (token.tvalue == 'FALSE')):\n",
    "                        token.tsubtype = self.TOK_SUBTYPE_LOGICAL\n",
    "                    else:\n",
    "                        token.tsubtype = self.TOK_SUBTYPE_RANGE\n",
    "                else:\n",
    "                    token.tsubtype = self.TOK_SUBTYPE_NUMBER\n",
    "                continue\n",
    "    \n",
    "            if (token.ttype == self.TOK_TYPE_FUNCTION):\n",
    "                if (token.tvalue[0:1] == \"@\"):\n",
    "                    token.tvalue = token.tvalue[1:]\n",
    "                continue\n",
    "    \n",
    "        tokens2.reset();\n",
    "    \n",
    "        # move all tokens to a new collection, excluding all noops\n",
    "        tokens = f_tokens()\n",
    "        while (tokens2.moveNext()):\n",
    "            if (tokens2.current().ttype != self.TOK_TYPE_NOOP):\n",
    "                tokens.addRef(tokens2.current())\n",
    "    \n",
    "        tokens.reset()\n",
    "        return tokens    \n",
    "\n",
    "    def parse(self, formula):\n",
    "        self.tokens = self.getTokens(formula)\n",
    "        \n",
    "    def render(self):\n",
    "        output = \"\"\n",
    "        if self.tokens:\n",
    "            for t in self.tokens.items:\n",
    "                if   t.ttype == self.TOK_TYPE_FUNCTION and t.tsubtype == self.TOK_SUBTYPE_START:     output += t.tvalue + \"(\"\n",
    "                elif t.ttype == self.TOK_TYPE_FUNCTION and t.tsubtype == self.TOK_SUBTYPE_STOP:      output += \")\"\n",
    "                elif t.ttype == self.TOK_TYPE_SUBEXPR  and t.tsubtype == self.TOK_SUBTYPE_START:     output += \"(\"\n",
    "                elif t.ttype == self.TOK_TYPE_SUBEXPR  and t.tsubtype == self.TOK_SUBTYPE_STOP:      output += \")\"\n",
    "                # TODO: add in RE substitution of \" with \"\" for strings\n",
    "                elif t.ttype == self.TOK_TYPE_OPERAND  and t.tsubtype == self.TOK_SUBTYPE_TEXT:      output += \"\\\"\" + t.tvalue + \"\\\"\"\n",
    "                elif t.ttype == self.TOK_TYPE_OP_IN    and t.tsubtype == self.TOK_SUBTYPE_INTERSECT: output += \" \"                    \n",
    "\n",
    "                else: output += t.tvalue\n",
    "        return output\n",
    "    \n",
    "    def prettyprint(self):\n",
    "        indent = 0\n",
    "        output = \"\"\n",
    "        if self.tokens:\n",
    "            for t in self.tokens.items:\n",
    "    \n",
    "                if (t.tsubtype == self.TOK_SUBTYPE_STOP):\n",
    "                    indent -= 1\n",
    "    \n",
    "                output += \"    \"*indent + t.tvalue + \" <\" + t.ttype +\"> <\" + t.tsubtype + \">\" + \"\\n\"\n",
    "                \n",
    "                if (t.tsubtype == self.TOK_SUBTYPE_START):\n",
    "                    indent += 1;\n",
    "        return output\n",
    "\n",
    "#========================================================================\n",
    "# Main code:\n",
    "#\n",
    "# A simple test-rig.  Iterate through a list of test input strings, \n",
    "# outputing a nested display of the token stream parsed from each one.\n",
    "#========================================================================\n",
    "if __name__ == \"__main1__\":\n",
    "    \n",
    "    # Test inputs\n",
    "    inputs = [\n",
    "              # Simple test formulae\n",
    "              '=1+3+5',\n",
    "              '=3 * 4 + 5',\n",
    "              '=50',\n",
    "              '=1+1',\n",
    "              '=$A1',\n",
    "              '=$B$2',\n",
    "              '=SUM(B5:B15)',\n",
    "              '=SUM(B5:B15,D5:D15)',\n",
    "              '=SUM(B5:B15 A7:D7)',\n",
    "              '=SUM(sheet1!$A$1:$B$2)',\n",
    "              '=[data.xls]sheet1!$A$1',\n",
    "              '=SUM((A:A 1:1))',\n",
    "              '=SUM((A:A,1:1))',\n",
    "              '=SUM((A:A A1:B1))',\n",
    "              '=SUM(D9:D11,E9:E11,F9:F11)',\n",
    "              '=SUM((D9:D11,(E9:E11,F9:F11)))',\n",
    "              '=IF(P5=1.0,\"NA\",IF(P5=2.0,\"A\",IF(P5=3.0,\"B\",IF(P5=4.0,\"C\",IF(P5=5.0,\"D\",IF(P5=6.0,\"E\",IF(P5=7.0,\"F\",IF(P5=8.0,\"G\"))))))))',\n",
    "              '={SUM(B2:D2*B3:D3)}',\n",
    "              '=SUM(123 + SUM(456) + (45<6))+456+789',\n",
    "              '=AVG(((((123 + 4 + AVG(A1:A2))))))',\n",
    "              \n",
    "              # E. W. Bachtal's test formulae\n",
    "              '=IF(\"a\"={\"a\",\"b\";\"c\",#N/A;-1,TRUE}, \"yes\", \"no\") &   \"  more \"\"test\"\" text\"',\n",
    "              '=+ AName- (-+-+-2^6) = {\"A\",\"B\"} + @SUM(R1C1) + (@ERROR.TYPE(#VALUE!) = 2)',\n",
    "              '=IF(R13C3>DATE(2002,1,6),0,IF(ISERROR(R[41]C[2]),0,IF(R13C3>=R[41]C[2],0, IF(AND(R[23]C[11]>=55,R[24]C[11]>=20),R53C3,0))))',\n",
    "              '=IF(R[39]C[11]>65,R[25]C[42],ROUND((R[11]C[11]*IF(OR(AND(R[39]C[11]>=55, ' + \n",
    "                  'R[40]C[11]>=20),AND(R[40]C[11]>=20,R11C3=\"YES\")),R[44]C[11],R[43]C[11]))+(R[14]C[11] ' +\n",
    "                  '*IF(OR(AND(R[39]C[11]>=55,R[40]C[11]>=20),AND(R[40]C[11]>=20,R11C3=\"YES\")), ' +\n",
    "                  'R[45]C[11],R[43]C[11])),0))',\n",
    "              ]\n",
    "\n",
    "    p = ExcelParser()\n",
    "\n",
    "    for i in inputs:\n",
    "        print (\"========================================\")\n",
    "        print (\"Formula:     \" + i)\n",
    "        p.parse(i)\n",
    "        print (\"Pretty printed:\\n\", p.prettyprint())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stack:\n",
    "    def __init__(self):\n",
    "        self.s = [] \n",
    "\n",
    "    def Empty(self):\n",
    "        return self.size() == 0\n",
    "\n",
    "    def Notempty(self):\n",
    "        return not self.Empty()\n",
    "\n",
    "    \n",
    "    def push(self, item, debug=True):\n",
    "        if (debug):\n",
    "            #print(\"Push :\", item );\n",
    "            ;\n",
    "        if (isinstance(item, Iterable) ):\n",
    "            for k in item:\n",
    "                self.s.append(k)\n",
    "        else:\n",
    "            self.s.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.s.pop()\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.s) \n",
    "    def dump():\n",
    "        l = str(self.s) if self.size() < 7 else str(self.s[0:9]) + \"...\" + str(self.s[-1])\n",
    "        o = \"Stack has {} items : {} \".format(self.size(), l)\n",
    "        \n",
    "    def EVAL(self, p, v=None):\n",
    "        t = self.pop()\n",
    "        print('Evaluating:', t.tostr())\n",
    "        o = \"\";\n",
    "        gotit = False\n",
    "        if (t.ttype == p.TOK_TYPE_FUNCTION and t.tsubtype == p.TOK_SUBTYPE_STOP):\n",
    "            gotit = True\n",
    "            print (\"Eval function:\");\n",
    "            o = \")\"\n",
    "            tt = self.pop();\n",
    "            while(tt.ttype != p.TOK_TYPE_FUNCTION and tt.tsubtype != p.TOK_SUBTYPE_START):\n",
    "                o = \",\" + str(tt.tvalue) + o;\n",
    "                tt = self.pop();\n",
    "            o = str(tt.tvalue) + \"( \" + o[1:];\n",
    "            print (o)\n",
    "            \n",
    "            ttt = f_token(o, p.TOK_TYPE_OPERAND, p.TOK_SUBTYPE_TEXT)\n",
    "            self.push(ttt)\n",
    "            print (\"Eval function: \", o , ttt);\n",
    "            \n",
    "        if (t.ttype == p.TOK_TYPE_OPERAND  and t.tsubtype == p.TOK_SUBTYPE_RANGE):\n",
    "            gotit = True\n",
    "            o = \"RANGE(\" +  t.tvalue + \")\";\n",
    "            ttt = f_token(o, p.TOK_TYPE_OPERAND, p.TOK_SUBTYPE_TEXT)\n",
    "            print (\"Eval RANGE: \", o , ttt);\n",
    "        \n",
    "        if ( not gotit ):\n",
    "            print (\"Hmmmm: \", t.tostr());\n",
    "            self.push(t)     \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
